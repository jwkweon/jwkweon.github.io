---
layout: single
title: '[논문] GAN : Generative Adversarial Nets - 작성중'
excerpt_separator: "<!--more-->"
categories:
  - Papers
tags:
  - 딥러닝
  - 생성모델

comments: true  
classes: wide
toc: false  
---
## [논문 Review] GAN (Generative Adversarial Nets)

이 논문은 2014년에 책 "Deep Learning"의 저자이자 한번쯤 이름을 들어봤을 딥러닝 대가 중 한분인 Ian Goodfellow가 발표한 논문이다. 이 논문이 발표된 이후 최근까지도 많은 GAN 논문들이 나오고 있을 정도로 딥러닝 생성모델의 분야에서 큰 영향을 끼친 논문이다.

> 논문링크 : [https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)

### Abstract
GAN의 큰 특징은 adversarial process를 통해 두 모델을 동시에 학습한다는 것입니다. 각 모델은 G(Generator)와 D(Discriminator)이며, G는 data distribution을 학습하며, D는 data sample이 training dataset에서 왔는지, G가 만들어낸 것인지 확률(training dataset에서 오면 1에 가까운 값)을 예측한다. 즉, D는 입력으로 들어온 data가 진짜인지(training set) 가짜인지(G)를 판별하는 것입니다.

학습과정에서 G는 D가 실수를 할 확률을 높이는 방향으로 학습하는데 이는 곳 G가 만들어내는 이미지가 D입장에서 진짜인지 가짜인지를 구별하지 못하게 만드는 것입니다.

임의의 G와 D에 대해 G는 training dataset 분포를 복구하며 D는 확률이 항상 1/2이 되는 유일한 솔루션이 정의됩니다.
G와 D의 네트워크는 MultiLayer Perceptrons(MLP)로 정의되면 두 네트워크는 backpropagation을 통해 학습할 수 있습니다.

### Introduction
지금까지 딥러닝에서 가장 발전적인 부분은 discriminative model과 관련되어 detection과 classification 문제와 같이 고차원의 풍부한 표현을 가진 입력에 대해 클래스의 label을 매핑하는 부분이었습니다. 그리고 이러한 동작은 back propagation이나 dropout 알고리즘을 기반으로 잘 동작했습니다.
하지만, 생성 모델의 경우 maximum likelihood estimation이나 관련한 방법들에서 발생하는 다루기 힘든 확률적 계산을 근사하기 어려웠고 생성의 맥락에서 부분적인 linear unit의 이점을 활용하기 어려워 큰 임팩트가 있지 않았습니다.
논문의 저자들은 이런 어려움을 회피하는 새로운 생성 모델을 제안하였습니다.

제안한 방법은 Adversarial Nets라는 생성 모델이며, Adversarial, 뜻 그대로 적대적인 관계에서 앞서 말한 두 모델 Generator와 Discriminator가 경쟁관계에서 서로의 성능을 높여주는 방향으로 학습을하는 것입니다.
논문에서 굉장히 재미있는 예시로 이를 설명합니다.

> 위조지폐범(Generator)과 경찰(Discriminator)이 있습니다. 위조지폐범은 위조지폐를 만들어 경찰을 속이려고 합니다. 하지만 경찰은 위조지폐범에게 속지 않고 가짜와 진짜를 구별하려고 합니다.
> 위조지폐범이 위조지폐를 만들때 처음에는 경찰을 잘 속이지는 못할 것 입니다. 위조지폐범은 경찰을 속이기위해 점점 더 진짜같은 위조지폐를 만들게 되고 경찰은 진짜 지폐와 점점 비슷해지는 위조지폐를 구별하기 위해 노력을 합니다.
> 결국 위조지폐범은 진짜같은 위조지폐를 만들게 되고 경찰은 어떤 것이 진짜인지 구별을 못해 반반(1/2)이라는 확률(unique solution)에 이르게 된됩니다.

이처럼 서로 경쟁적으로 학습을 진행하며 두 모델의 성능을 높여나가는 것이 GAN의 큰 개념입니다.

Generator와 Discriminator는 모두 MLP이며 Generator의 경우 랜덤 노이즈를 입력으로 넣어 샘플을 생성합니다. Back propagation과 dropout 알고리즘을 사용하여 두 모델을 학습했으며 forward propagation을 통해서 샘플을 추출합니다.
